{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Load the Car Evaluation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_car=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "# Load dataset\n",
    "df_car = pd.read_csv('car.data',delim_whitespace=False, header=None)\n",
    "\n",
    "df_car.columns=col_names_car\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df_car.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Encode categorical features to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in df_car.columns:\n",
    "    df_car[col] = label_encoder.fit_transform(df_car[col])\n",
    "\n",
    "df_car.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 - Split the Data into a training (80%) and a test set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X=df_car.iloc[:, :-1]\n",
    "y=df_car.iloc[:, -1]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 - Train a multilayer perceptron.  Experiment with Different MLP Configurations and record the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configurations\n",
    "configs=[(32,),(64,),(32, 16),(64, 32),(64, 32, 16)]\n",
    "\n",
    "# Define an empty array\n",
    "results=[]\n",
    "\n",
    "for config in configs:\n",
    "    mlp=MLPClassifier(hidden_layer_sizes=config, max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred=mlp.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    results.append({'config': config, 'accuracy': accuracy})\n",
    "    print(f\"Config: {config}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Find the best configuration\n",
    "best_config=max(results, key=lambda x: x['accuracy'])\n",
    "print(f\"Best Configuration: {best_config['config']}, Accuracy: {best_config['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 - For the best-performing MLP configuration experiment with different training sizes (10%-70%) and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "training_results=[]\n",
    "\n",
    "for size in training_sizes:\n",
    "    X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, train_size=size, random_state=42)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=best_config['config'], max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train_small, y_train_small)\n",
    "    y_pred=mlp.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    training_results.append({'size': size, 'accuracy': accuracy})\n",
    "    print(f\"Training Size: {size}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 - Plot the training loss curve for the different training set sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training loss curve for different training set sizes\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for size in training_sizes:\n",
    "    X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, train_size=size, random_state=42)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=best_config['config'], max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train_small, y_train_small)\n",
    "    plt.plot(mlp.loss_curve_, label=f'Train Size: {int(size * 100)}%')\n",
    "\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto MPG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Load and Preprocess the Auto MPG Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_auto=['mpg', 'cylinders', 'displacement', 'horsepower','weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "\n",
    "# Load the dataset\n",
    "df_auto=pd.read_csv('auto-mpg.data', delim_whitespace=True, names=col_names_auto)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_auto.head())\n",
    "\n",
    "# Handle missing values\n",
    "df_auto['horsepower']=pd.to_numeric(df_auto['horsepower'], errors='coerce')\n",
    "df_auto=df_auto.dropna()\n",
    "\n",
    "# Drop the car_name column as it is not relevant\n",
    "df_auto=df_auto.drop(columns=['car_name'])\n",
    "\n",
    "# Display dataset totaly\n",
    "print(\"\\n\")\n",
    "print(\"Total\")\n",
    "print(df_auto.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Split Data into a training (70%) and a test set (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X=df_auto.drop(columns=['mpg'])\n",
    "y=df_auto['mpg']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 - Standardize the feature values to have zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 - Build and Train the MLP Regressor. Use hidden layers with sizes (64, 32, 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP Regressor\n",
    "mlp=MLPRegressor(hidden_layer_sizes=(64, 32, 16),activation='relu',solver='adam',max_iter=500,random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred=mlp.predict(X_test_scaled)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 - Evaluate the Model the model's performance using Mean Squared Error (MSE) and Mean Absolute Error (MAE) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE and MAE\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "mae=mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 - Show Predictions vs. Actual Values \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for comparison\n",
    "results_df = pd.DataFrame({'Actual': y_test,'Predicted': y_pred})\n",
    "\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7 - Plot the training loss curve to visualize model convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(mlp.loss_curve_, label='Training Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
